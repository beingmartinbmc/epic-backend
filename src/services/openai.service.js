import dotenv from 'dotenv';
import { getCustomMetric } from '../config/actuator.js';

dotenv.config();

/**
 * OpenAI API Service
 */
export class OpenAIService {
  constructor() {
    this.apiKey = process.env.OPENAI_API_KEY;
    this.model = 'gpt-4.1-nano';
    this.maxTokens = parseInt(process.env.OPENAI_TOKEN) || 1000;
    this.baseTemperature = parseFloat(process.env.OPENAI_TEMPERATURE) || 0.8;

    if (!this.apiKey) {
      throw new Error('OPENAI_API_KEY environment variable is required');
    }
  }

  /**
   * Extract selected text option from user message
   * @param {string} userMessage - User's message
   * @returns {string} - Selected text option
   */
  extractSelectedText(userMessage) {
    if (userMessage.includes('from EACH of the following:')) {
      return 'ALL';
    } else if (userMessage.includes('Bhagavad Gita')) {
      return 'BHAGAVAD_GITA';
    } else if (userMessage.includes('Vedas')) {
      return 'VEDAS';
    } else if (userMessage.includes('Quran')) {
      return 'QURAN';
    } else if (userMessage.includes('Bible')) {
      return 'BIBLE';
    } else if (userMessage.includes('Guru Granth Sahib')) {
      return 'GURU_GRANTH_SAHIB';
    }
    return 'ALL';
  }

  /**
   * Generate randomized temperature for diversity
   * @returns {number} - Randomized temperature value
   */
  generateRandomizedTemperature() {
    const temperatureVariance = 0.15;
    return Math.min(1.0, Math.max(0.6,
      this.baseTemperature + (Math.random() - 0.5) * temperatureVariance * 2
    ));
  }

  /**
   * Add diversity instruction to prevent repetitive quotes
   * @param {Array} messages - Original messages array
   * @returns {Array} - Modified messages with diversity instruction
   */
  addDiversityInstruction(messages) {
    const diversityInstruction =
      'IMPORTANT: Provide diverse quotes from different chapters and verses. ' +
      'Avoid repeating the same quotes. Each response should include quotes from ' +
      'various parts of the scripture to provide comprehensive guidance.';

    return messages.map((msg) => {
      if (msg.role === 'system') {
        return {
          ...msg,
          content: `${msg.content}\n\n${diversityInstruction}`
        };
      }
      return msg;
    });
  }

  /**
   * Make API call to OpenAI with retry logic
   * @param {Object} requestData - Request data
   * @param {number} retries - Number of retries
   * @returns {Promise<Object>} - OpenAI API response
   */
  async makeAPICall(requestData, retries = 3) {
    const startTime = Date.now();

    for (let attempt = 1; attempt <= retries; attempt++) {
      try {
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${this.apiKey}`
          },
          body: JSON.stringify(requestData)
        });

        if (!response.ok) {
          const errorData = await response.json().catch(() => ({}));
          throw new Error(`OpenAI API error: ${response.status} - ${errorData.error?.message || response.statusText}`);
        }

        const data = await response.json();

        // Record metrics
        this.recordMetrics(startTime, data);

        return data;
      } catch (error) {
        console.error(`‚ùå OpenAI API attempt ${attempt} failed:`, error.message);

        if (attempt === retries) {
          throw error;
        }

        // Exponential backoff
        const delay = Math.min(1000 * Math.pow(2, attempt - 1), 10000);
        await new Promise((resolve) => setTimeout(resolve, delay));
      }
    }
  }

  /**
   * Record metrics for monitoring
   * @param {number} startTime - Start time of the request
   * @param {Object} _data - Response data
   */
  recordMetrics(startTime, _data) {
    try {
      const responseTime = (Date.now() - startTime) / 1000;

      // Record response time
      const responseTimeHistogram = getCustomMetric('epic_response_time_seconds');
      if (responseTimeHistogram) {
        responseTimeHistogram.observe(responseTime);
        console.log(`‚úÖ Recorded response time: ${responseTime.toFixed(3)}s`);
      }

      // Record conversation count
      const conversationsCounter = getCustomMetric('epic_conversations_total');
      if (conversationsCounter) {
        conversationsCounter.inc();
        console.log('‚úÖ Incremented epic_conversations_total');
      }
    } catch (error) {
      console.error('‚ùå Error recording metrics:', error.message);
    }
  }

  /**
   * Generate chat completion
   * @param {Array} messages - Array of message objects
   * @param {Object} options - Optional parameters to override defaults
   * @returns {Promise<Object>} - Generated response
   */
  async generateChatCompletion(messages, options = {}) {
    try {
      // Extract user message for analysis
      const userMessage = messages.find((msg) => msg.role === 'user')?.content || '';
      const selectedText = this.extractSelectedText(userMessage);

      // Prepare request data with options override
      const requestData = {
        model: options.model || this.model,
        messages: options.skipDiversityInstruction ? messages : this.addDiversityInstruction(messages),
        temperature: options.temperature || this.generateRandomizedTemperature(),
        max_tokens: options.maxTokens || this.maxTokens,
        top_p: options.topP || 0.85,
        frequency_penalty: options.frequencyPenalty || 0.4,
        presence_penalty: options.presencePenalty || 0.2,
        stop: options.stop || null
      };

      console.log('üöÄ Making OpenAI API request...');
      const data = await this.makeAPICall(requestData);

      if (!data.choices || data.choices.length === 0) {
        throw new Error('No response generated from OpenAI API');
      }

      return {
        data,
        metadata: {
          selectedText,
          model: requestData.model,
          temperature: requestData.temperature,
          maxTokens: requestData.max_tokens,
          usage: data.usage || {},
          requestId: data.id,
          customOptions: options
        }
      };
    } catch (error) {
      console.error('‚ùå Error generating chat completion:', error.message);

      // Record error metric
      const errorsCounter = getCustomMetric('epic_errors_total');
      if (errorsCounter) {
        errorsCounter.inc();
      }

      throw error;
    }
  }

  /**
   * Generate streaming chat completion
   * @param {Array} messages - Array of messages
   * @param {Object} res - Express response object
   * @param {Object} options - Optional parameters for customization
   * @returns {Promise<void>} - Streams response to client
   */
  async generateStreamingChatCompletion(messages, res, options = {}) {
    try {
      const selectedText = this.extractSelectedText(
        messages.find(msg => msg.role === 'user')?.content || ''
      );

      // Record API call metric
      const apiCallsCounter = getCustomMetric('epic_api_calls_total');
      if (apiCallsCounter) {
        apiCallsCounter.inc();
      }

      // Add diversity instruction
      const diversifiedMessages = this.addDiversityInstruction(messages);

      // Prepare request data for streaming
      const requestData = {
        model: options.model || this.model,
        messages: diversifiedMessages,
        max_tokens: options.maxTokens || this.maxTokens,
        temperature: options.temperature || this.generateRandomizedTemperature(),
        stream: true, // Enable streaming
        stream_options: {
          include_usage: true
        }
      };

      console.log(`üöÄ Starting streaming request to OpenAI API...`);

      // Make streaming API call
      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: JSON.stringify(requestData)
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        throw new Error(`OpenAI API error: ${response.status} - ${errorData.error?.message || response.statusText}`);
      }

      console.log(`‚úÖ Streaming response received, processing chunks...`);

      // Send initial metadata
      res.write(`event: start\n`);
      res.write(`data: ${JSON.stringify({
        selectedText,
        model: requestData.model,
        temperature: requestData.temperature,
        maxTokens: requestData.max_tokens
      })}\n\n`);

      // Process streaming response
      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let buffer = '';
      let totalTokens = 0;

      try {
        while (true) {
          const { done, value } = await reader.read();
          
          if (done) {
            break;
          }

          buffer += decoder.decode(value, { stream: true });
          const lines = buffer.split('\n');
          buffer = lines.pop() || '';

          for (const line of lines) {
            if (line.startsWith('data: ')) {
              const data = line.slice(6);
              
              if (data === '[DONE]') {
                // Send completion event
                res.write(`event: done\n`);
                res.write(`data: ${JSON.stringify({
                  totalTokens,
                  selectedText,
                  timestamp: new Date().toISOString()
                })}\n\n`);
                res.end();
                return;
              }

              try {
                const parsed = JSON.parse(data);
                
                if (parsed.choices && parsed.choices[0]) {
                  const delta = parsed.choices[0].delta;
                  
                  if (delta.content) {
                    // Send content chunk
                    res.write(`event: chunk\n`);
                    res.write(`data: ${JSON.stringify({
                      content: delta.content,
                      timestamp: new Date().toISOString()
                    })}\n\n`);
                  }

                  // Track usage if available
                  if (parsed.usage) {
                    totalTokens = parsed.usage.total_tokens;
                  }
                }
              } catch (parseError) {
                console.warn('‚ö†Ô∏è Failed to parse streaming chunk:', parseError.message);
              }
            }
          }
        }
      } finally {
        reader.releaseLock();
      }

      // Record success metric
      const successCounter = getCustomMetric('epic_successful_requests_total');
      if (successCounter) {
        successCounter.inc();
      }

    } catch (error) {
      console.error('‚ùå Error in streaming chat completion:', error.message);

      // Record error metric
      const errorsCounter = getCustomMetric('epic_errors_total');
      if (errorsCounter) {
        errorsCounter.inc();
      }

      // Send error event
      res.write(`event: error\n`);
      res.write(`data: ${JSON.stringify({
        error: 'Stream processing failed',
        message: error.message,
        timestamp: new Date().toISOString()
      })}\n\n`);
      
      res.end();
    }
  }

  /**
   * Generate streaming voice completion (OpenAI + Deepgram TTS)
   * @param {Array} messages - Array of messages
   * @param {Object} res - Express response object
   * @param {Object} voiceSettings - Voice configuration options
   * @returns {Promise<void>} - Streams voice response to client
   */
  async generateStreamingVoiceCompletion(messages, res, voiceSettings = {}) {
    try {
      const selectedText = this.extractSelectedText(
        messages.find(msg => msg.role === 'user')?.content || ''
      );

      // Voice configuration
      const {
        model = 'aura-2-draco-en',
        chunkSize = 50, // Words per audio chunk
        bufferAudio = true
      } = voiceSettings;

      // Record API call metric
      const apiCallsCounter = getCustomMetric('epic_api_calls_total');
      if (apiCallsCounter) {
        apiCallsCounter.inc();
      }

      // Add diversity instruction
      const diversifiedMessages = this.addDiversityInstruction(messages);

      // Prepare request data for streaming
      const requestData = {
        model: this.model,
        messages: diversifiedMessages,
        max_tokens: this.maxTokens,
        temperature: this.generateRandomizedTemperature(),
        stream: true,
        stream_options: {
          include_usage: true
        }
      };

      console.log(`üé§ Starting streaming voice request...`);

      // Send initial metadata
      res.write(`event: start\n`);
      res.write(`data: ${JSON.stringify({
        selectedText,
        model: requestData.model,
        voiceModel: model,
        chunkSize,
        timestamp: new Date().toISOString()
      })}\n\n`);

      // Make streaming API call to OpenAI
      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: JSON.stringify(requestData)
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        throw new Error(`OpenAI API error: ${response.status} - ${errorData.error?.message || response.statusText}`);
      }

      // Process streaming response and convert to voice
      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let buffer = '';
      let textBuffer = '';
      let totalTokens = 0;
      let chunkIndex = 0;

      try {
        while (true) {
          const { done, value } = await reader.read();
          
          if (done) {
            // Process any remaining text in buffer
            if (textBuffer.trim()) {
              await this.convertTextToSpeech(textBuffer.trim(), res, chunkIndex++, model);
            }
            break;
          }

          buffer += decoder.decode(value, { stream: true });
          const lines = buffer.split('\n');
          buffer = lines.pop() || '';

          for (const line of lines) {
            if (line.startsWith('data: ')) {
              const data = line.slice(6);
              
              if (data === '[DONE]') {
                // Send completion event
                res.write(`event: done\n`);
                res.write(`data: ${JSON.stringify({
                  totalTokens,
                  totalChunks: chunkIndex,
                  selectedText,
                  timestamp: new Date().toISOString()
                })}\n\n`);
                res.end();
                return;
              }

              try {
                const parsed = JSON.parse(data);
                
                if (parsed.choices && parsed.choices[0]) {
                  const delta = parsed.choices[0].delta;
                  
                  if (delta.content) {
                    textBuffer += delta.content;
                    
                    // Send text chunk for real-time display
                    res.write(`event: text\n`);
                    res.write(`data: ${JSON.stringify({
                      content: delta.content,
                      timestamp: new Date().toISOString()
                    })}\n\n`);

                    // Check if we have enough text for audio conversion
                    const words = textBuffer.split(' ');
                    if (words.length >= chunkSize) {
                      const chunkText = words.slice(0, chunkSize).join(' ');
                      textBuffer = words.slice(chunkSize).join(' ');
                      
                      // Convert to speech asynchronously
                      await this.convertTextToSpeech(chunkText, res, chunkIndex++, model);
                    }
                  }

                  // Track usage if available
                  if (parsed.usage) {
                    totalTokens = parsed.usage.total_tokens;
                  }
                }
              } catch (parseError) {
                console.warn('‚ö†Ô∏è Failed to parse streaming chunk:', parseError.message);
              }
            }
          }
        }
      } finally {
        reader.releaseLock();
      }

      // Record success metric
      const successCounter = getCustomMetric('epic_successful_requests_total');
      if (successCounter) {
        successCounter.inc();
      }

    } catch (error) {
      console.error('‚ùå Error in streaming voice completion:', error.message);

      // Record error metric
      const errorsCounter = getCustomMetric('epic_errors_total');
      if (errorsCounter) {
        errorsCounter.inc();
      }

      // Send error event
      res.write(`event: error\n`);
      res.write(`data: ${JSON.stringify({
        error: 'Voice streaming failed',
        message: error.message,
        timestamp: new Date().toISOString()
      })}\n\n`);
      
      res.end();
    }
  }

  /**
   * Convert text to speech using Deepgram and stream as base64
   * @param {string} text - Text to convert
   * @param {Object} res - Response object
   * @param {number} chunkIndex - Audio chunk index
   * @param {string} voiceModel - Deepgram voice model
   */
  async convertTextToSpeech(text, res, chunkIndex, voiceModel) {
    try {
      const voiceKey = process.env.VOICE_KEY;
      if (!voiceKey) {
        console.warn('‚ö†Ô∏è VOICE_KEY not configured, skipping TTS');
        return;
      }

      console.log(`üéµ Converting chunk ${chunkIndex} to speech: "${text.substring(0, 50)}..."`);

      const response = await fetch(`https://api.deepgram.com/v1/speak?model=${voiceModel}`, {
        method: 'POST',
        headers: {
          'Authorization': `Token ${voiceKey}`,
          'Content-Type': 'text/plain'
        },
        body: text
      });

      if (!response.ok) {
        console.warn(`‚ö†Ô∏è Deepgram TTS failed for chunk ${chunkIndex}:`, response.status);
        return;
      }

      // Get audio buffer and convert to base64
      const audioBuffer = Buffer.from(await response.arrayBuffer());
      const base64Audio = audioBuffer.toString('base64');

      // Send audio chunk
      res.write(`event: audio\n`);
      res.write(`data: ${JSON.stringify({
        chunkIndex,
        audio: base64Audio,
        text,
        mimeType: 'audio/mpeg',
        timestamp: new Date().toISOString()
      })}\n\n`);

      console.log(`‚úÖ Audio chunk ${chunkIndex} sent (${audioBuffer.length} bytes)`);

    } catch (error) {
      console.error(`‚ùå TTS conversion failed for chunk ${chunkIndex}:`, error.message);
      
      // Send error for this specific chunk, but continue processing
      res.write(`event: audio-error\n`);
      res.write(`data: ${JSON.stringify({
        chunkIndex,
        text,
        error: error.message,
        timestamp: new Date().toISOString()
      })}\n\n`);
    }
  }
}

// Export singleton instance
export const openAIService = new OpenAIService();
